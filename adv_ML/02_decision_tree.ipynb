{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 2 - Assignment\n",
    "\n",
    "In this assignment, you will implement a Decision Tree algorithm from scratch and compare the results to existing sklearn algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# make this notebook's output stable across runs\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE\n",
    "\n",
    "### I decided to use pandas instead of a list to represent the data, just because I found it easier to understand what was actually going on that way than when it was represented as just a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.66610</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.16740</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.63830</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.52280</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.45520</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>0.40614</td>\n",
       "      <td>1.34920</td>\n",
       "      <td>-1.4501</td>\n",
       "      <td>-0.55949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>-1.38870</td>\n",
       "      <td>-4.87730</td>\n",
       "      <td>6.4774</td>\n",
       "      <td>0.34179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>-3.75030</td>\n",
       "      <td>-13.45860</td>\n",
       "      <td>17.5932</td>\n",
       "      <td>-2.77710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>-3.56370</td>\n",
       "      <td>-8.38270</td>\n",
       "      <td>12.3930</td>\n",
       "      <td>-1.28230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>-2.54190</td>\n",
       "      <td>-0.65804</td>\n",
       "      <td>2.6842</td>\n",
       "      <td>1.19520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1372 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            A         B        C        D  target\n",
       "0     3.62160   8.66610  -2.8073 -0.44699       0\n",
       "1     4.54590   8.16740  -2.4586 -1.46210       0\n",
       "2     3.86600  -2.63830   1.9242  0.10645       0\n",
       "3     3.45660   9.52280  -4.0112 -3.59440       0\n",
       "4     0.32924  -4.45520   4.5718 -0.98880       0\n",
       "...       ...       ...      ...      ...     ...\n",
       "1367  0.40614   1.34920  -1.4501 -0.55949       1\n",
       "1368 -1.38870  -4.87730   6.4774  0.34179       1\n",
       "1369 -3.75030 -13.45860  17.5932 -2.77710       1\n",
       "1370 -3.56370  -8.38270  12.3930 -1.28230       1\n",
       "1371 -2.54190  -0.65804   2.6842  1.19520       1\n",
       "\n",
       "[1372 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn = 'data_banknote_authentication.csv'\n",
    "df = pd.read_csv(fn, header=None)\n",
    "df.columns = ['A', 'B', 'C', 'D', 'target']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1.1: Implement the functions to calculate Gini Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the Gini index for a split dataset\n",
    "def gini_index(groups, classes, target_col='target'):\n",
    "    total_instances = float(sum([len(group) for group in groups]))\n",
    "    gini = 0.0\n",
    "    for group in groups:\n",
    "        size = float(len(group))\n",
    "        if size == 0:\n",
    "            continue\n",
    "        score = 0.0\n",
    "        for class_val in classes:\n",
    "            p = (group[target_col] == class_val).sum() / size\n",
    "            score += p**2\n",
    "        gini += (1 - score) * (size / total_instances)\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2.1: Write a method that splits the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pandas version\n",
    "# Split a dataset based on an attribute and an attribute value\n",
    "def test_split(df, feature, value):\n",
    "    left = df[df[feature] < value]\n",
    "    right = df[df[feature] >= value]\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2.2: Write a method that loops over the dataset, determine the groups of rows that belong to the right or left split, and calculates the gini_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pandas version\n",
    "def get_split(df, target_col='target'):\n",
    "    class_values = df[target_col].unique()\n",
    "    best_feature, best_value, best_score, best_groups = 999, 999, 999, None\n",
    "    for feature in df.columns:\n",
    "        if feature == target_col:\n",
    "            continue\n",
    "        for index in df.index:\n",
    "            value = df.loc[index][feature]\n",
    "            groups = test_split(df, feature, value)\n",
    "            gini = gini_index(groups, class_values)\n",
    "            if gini < best_score:\n",
    "                best_feature, best_value, best_score, best_groups = feature, value, gini, groups\n",
    "    return {\n",
    "        'feature': best_feature,\n",
    "        'value': best_value,\n",
    "        'groups': best_groups\n",
    "    }\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2.3: Repeat question 2.2 using entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy_score(groups, classes, target_col='target'):\n",
    "    total_instances = float(sum([len(group) for group in groups]))\n",
    "    entropy = 0.0\n",
    "    for group in groups:\n",
    "        size = float(len(group))\n",
    "        if size == 0:\n",
    "            continue\n",
    "        score = 0.0\n",
    "        for class_val in classes:\n",
    "            p = (group[target_col] == class_val).sum() / size\n",
    "            score += p * np.log(p)\n",
    "        entropy += -score * (size / total_instances)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_split_entropy(dataset):\n",
    "    class_values = df[target_col].unique()\n",
    "    best_feature, best_value, best_score, best_groups = 999, 999, 999, None\n",
    "    for feature in df.columns:\n",
    "        if feature == target_col:\n",
    "            continue\n",
    "        for index in df.index:\n",
    "            value = df.loc[index][feature]\n",
    "            groups = test_split(df, feature, value)\n",
    "            entropy = entropy_score(groups, class_values)\n",
    "            if entropy < best_score:\n",
    "                best_feature, best_value, best_score, best_groups = feature, value, entropy, groups\n",
    "    return {\n",
    "        'feature': best_feature,\n",
    "        'value': best_value,\n",
    "        'groups': best_groups\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3.1: Write a method that takes in a group of rows and determines the class they belongs to. It should return the most common output value for a list of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pandas version\n",
    "def to_terminal(group, target_col='target'):\n",
    "    return group[target_col].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3.2: Write a method that recursively split the data.\n",
    "The method takes in a node, max_depth, min_size, and depth. Initially, the method would be called by passing the rood node and depth of 1. Here are the steps to help you implement:\n",
    "\n",
    "- First, we create two groups for the data split and delete any existing groups from the node. As rows are used, they are no longer needed.\n",
    "- Second, check if rows should be in left or right group, and if so we create a terminal node using the records we have.\n",
    "- Third, check if maximum depth is reached and if so we create a terminal node.\n",
    "- Fourth, process left child, creating a terminal node if the group of rows is too small, otherwise creating and adding the left node in a depth first fashion until the bottom of the tree is reached on this branch.\n",
    "- Fifth, process the right side in a similar manner as left side, as we rise back up the constructed tree to the root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pandas version\n",
    "def split(node, max_depth, min_size, depth):\n",
    "    left, right = node['groups']\n",
    "    del(node['groups'])\n",
    "    if left.empty or right.empty:\n",
    "        terminal_val = to_terminal(pd.concat([left, right]))\n",
    "        node['left'] = terminal_val\n",
    "        node['right'] = terminal_val\n",
    "        return\n",
    "    if depth >= max_depth:\n",
    "        node['right'] = to_terminal['right']\n",
    "        node['left'] = to_terminal['left']\n",
    "        return\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_split(left)\n",
    "        split(node['left'], max_depth, min_size, depth+1)\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        node['right'] = get_split(right)\n",
    "        split(node['right'], max_depth, min_size, depth+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3.3: Write a method that builds the tree. The method creates an initial split to determine root node, and then calls the split method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build a decision tree\n",
    "def build_tree(train, max_depth, min_size):\n",
    "    \"TODO get the first split, and then split starting fromt the root\"\n",
    "    root = get_split(train)\n",
    "    split(root, max_depth, min_size, 1)\n",
    "    return root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3.4: Write a method that takes in a node and rows of data, and predicts the class associated with each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pandas version\n",
    "# Make a prediction with a decision tree\n",
    "def predict(node, row):\n",
    "    #TODO check if a row belongs to a node and recursively traverse the tree if the row doesn't.\n",
    "    if row[node['feature']] < node['value']:\n",
    "        if type(node['left']) is dict:\n",
    "            return predict(node['left'], row)\n",
    "        else:\n",
    "            return node['left']\n",
    "    else:\n",
    "        if type(node['right']) is dict:\n",
    "            return predict(node['right'], row)\n",
    "        else:\n",
    "            return node['right']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4: Train a decision tree using the banknote_authentication data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pandas version\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from csv import reader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load a CSV file\n",
    "def load_csv(filename):\n",
    "    df = pd.read_csv(filename, header=None)\n",
    "    df.columns = ['A', 'B', 'C', 'D', 'target']\n",
    "    return df\n",
    "       \n",
    "filename = 'data_banknote_authentication.csv'\n",
    "df = load_csv(filename)\n",
    "\n",
    "# the data is sorted by class so this version will have a test set that contains only positive samples\n",
    "# train = df[1:int(len(df)*2/3)]\n",
    "# test = df[int(len(df)*2/3)+1:len(df)]\n",
    "\n",
    "# i'll use train_test_split instead\n",
    "train, test = train_test_split(df, test_size=2/3, random_state=99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: the below might be a little slower than normal, due to the overhead of iterrows(). But it does work! It took about ~12 seconds when I tried it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9508196721311475\n"
     ]
    }
   ],
   "source": [
    "#TODO Build a tree and evalute accuracy\n",
    "tree = build_tree(train, max_depth=100, min_size=1)\n",
    "predictions = list()\n",
    "for index, row in test.iterrows():\n",
    "    prediction = predict(tree, row)\n",
    "    predictions.append(prediction)\n",
    "               \n",
    "print('Accuracy: %s' % accuracy_score(test['target'], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Bonus] Question 5: Train and evaluate an SKLEARN decision tree model, and compare the results to your model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9628415300546448\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "features = ['A', 'B', 'C', 'D']\n",
    "clf = DecisionTreeClassifier().fit(train[features], train['target'])\n",
    "predictions = clf.predict(test[features])\n",
    "\n",
    "print('Accuracy: %s' % accuracy_score(test['target'], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 6: Create a new text cell in your Notebook: Complete a 50-100 word summary (or short description of your thinking in applying this week's learning to the solution) of your experience in this assignment. Include: What was your incoming experience with this model, if any? what steps you took, what obstacles you encountered. how you link this exercise to real-world, machine learning problem-solving. (What steps were missing? What else do you need to learn?) This summary allows your instructor to know how you are doing and allot points for your effort in thinking and planning, and making connections to real-world work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to this assignment, I had no experience with decision trees, so this is truly new material for me. I decided to use pandas to work with the data instead of a raw list of lists. I'm not sure if that was slower; it's possible it was since I mostly used the framework already provided, rather than really taking advantage of pandas vector methods. I'm sure this added some overhead since doing things like iterrows() is really slow in pandas. But it was helpful because then I had a better grasp of what the data was doing at each step, since I am used to working with pandas. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [3.7]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
